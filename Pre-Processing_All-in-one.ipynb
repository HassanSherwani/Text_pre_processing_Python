{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate_speech-Pre-processing excercise\n",
    "Special thanks to VidyaAnalytica tutorials that helped me in this excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "To preprocess dataset for future use of supervised and unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's be rebels and ignore warnings for now\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)-Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...\n",
       "6   7      0   @user camping tomorrow @user @user @user @use...\n",
       "7   8      0  the next school year is the year for exams.ð...\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s check out a few non racist/sexist tweets.\n",
    "\n",
    "train[train['label'] == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>it's unbelievable that in the 21st century we'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>@user lets fight against  #love #peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>ð©the white establishment can't have blk fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>@user hey, white people: you can call people '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>how the #altright uses  &amp;amp; insecurity to lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>@user i'm not interested in a #linguistics tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet\n",
       "13    14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14    15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "17    18      1                             retweet if you agree! \n",
       "23    24      1    @user @user lumpy says i am a . prove it lumpy.\n",
       "34    35      1  it's unbelievable that in the 21st century we'...\n",
       "56    57      1            @user lets fight against  #love #peace \n",
       "68    69      1  ð©the white establishment can't have blk fol...\n",
       "77    78      1  @user hey, white people: you can call people '...\n",
       "82    83      1  how the #altright uses  &amp; insecurity to lu...\n",
       "111  112      1  @user i'm not interested in a #linguistics tha..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out a few racist/sexist tweets.\n",
    "\n",
    "train[train['label'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)-Basic feature extraction using text data\n",
    "- Number of words\n",
    "- Number of characters\n",
    "- Average word length\n",
    "- Number of stopwords\n",
    "- Number of special characters\n",
    "- Number of numerics\n",
    "- Number of uppercase words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)- Number of words\n",
    "One of the most basic features we can extract is the number of words in each tweet. The basic intuition behind this is that generally, the negative sentiments contain a lesser amount of words than the positive ones.\n",
    "\n",
    "To do this, we simply use the split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0   @user when a father is dysfunctional and is s...          21\n",
       "1  @user @user thanks for #lyft credit i can't us...          22\n",
       "2                                bihday your majesty           5\n",
       "3  #model   i love u take with u all the time in ...          17\n",
       "4             factsguide: society now    #motivation           8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['word_count'] = train['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train[['tweet','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)-Number of characters\n",
    "This feature is also based on the previous feature intuition. Here, we calculate the number of characters in each tweet(space, special character included). This is done by calculating the length of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  char_count\n",
       "0   @user when a father is dysfunctional and is s...         102\n",
       "1  @user @user thanks for #lyft credit i can't us...         122\n",
       "2                                bihday your majesty          21\n",
       "3  #model   i love u take with u all the time in ...          86\n",
       "4             factsguide: society now    #motivation          39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['char_count'] = train['tweet'].str.len() ## this also includes spaces\n",
    "train[['tweet','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26a9b5a1a20>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_train = train['tweet'].str.len() \n",
    "plt.hist(length_train, bins=20, label=\"train_tweets\") \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3)- Average Word Length\n",
    "Take the sum of the length of all the words and divide it by the total length of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>4.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>5.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>4.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  avg_word\n",
       "0   @user when a father is dysfunctional and is s...  4.555556\n",
       "1  @user @user thanks for #lyft credit i can't us...  5.315789\n",
       "2                                bihday your majesty  5.666667\n",
       "3  #model   i love u take with u all the time in ...  4.928571\n",
       "4             factsguide: society now    #motivation  8.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['tweet'].apply(lambda x: avg_word(x))\n",
    "train[['tweet','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4)-Number of stopwords\n",
    " Some examples are \"the, is, at, which, and, on\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  stopwords\n",
       "0   @user when a father is dysfunctional and is s...         10\n",
       "1  @user @user thanks for #lyft credit i can't us...          5\n",
       "2                                bihday your majesty          1\n",
       "3  #model   i love u take with u all the time in ...          5\n",
       "4             factsguide: society now    #motivation          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopwords'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['tweet','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5)-Number of special characters\n",
    "- One easy example is number of hashtags\n",
    "- Use of the ‘starts with’ function because hashtags (or mentions) always appear at the beginning of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  hastags\n",
       "0   @user when a father is dysfunctional and is s...        1\n",
       "1  @user @user thanks for #lyft credit i can't us...        3\n",
       "2                                bihday your majesty        0\n",
       "3  #model   i love u take with u all the time in ...        1\n",
       "4             factsguide: society now    #motivation        1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hastags'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "train[['tweet','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6)-Number of numerics/digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  numerics\n",
       "0   @user when a father is dysfunctional and is s...         0\n",
       "1  @user @user thanks for #lyft credit i can't us...         0\n",
       "2                                bihday your majesty         0\n",
       "3  #model   i love u take with u all the time in ...         0\n",
       "4             factsguide: society now    #motivation         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['numerics'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "train[['tweet','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7)-Number of Uppercase words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  upper\n",
       "0   @user when a father is dysfunctional and is s...      0\n",
       "1  @user @user thanks for #lyft credit i can't us...      0\n",
       "2                                bihday your majesty      0\n",
       "3  #model   i love u take with u all the time in ...      0\n",
       "4             factsguide: society now    #motivation      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['upper'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "train[['tweet','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)-Basic Text Pre-processing of text data\n",
    "- Lower casing\n",
    "- Punctuation removal\n",
    "- Stopwords removal\n",
    "- Frequent words removal\n",
    "- Rare words removal\n",
    "- Spelling correction\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)-Lower case\n",
    "First pre-processing step which we will do is transform our tweets into lower case. This avoids having multiple copies of the same words. For example, while calculating the word count, ‘Father’ and ‘father’ will be taken as different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @user when a father is dysfunctional and is so...\n",
       "1    @user @user thanks for #lyft credit i can't us...\n",
       "2                                  bihday your majesty\n",
       "3    #model i love u take with u all the time in ur...\n",
       "4                  factsguide: society now #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)-Removing Punctuation\n",
    "removing em will help us reduce the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user when a father is dysfunctional and is so ...\n",
       "1    user user thanks for lyft credit i cant use ca...\n",
       "2                                  bihday your majesty\n",
       "3    model i love u take with u all the time in urð...\n",
       "4                    factsguide society now motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'] = train['tweet'].str.replace('[^\\w\\s]','')\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user user thanks for lyft credit i cant use cause they dont offer wheelchair vans in pdx disapointed getthanked'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['tweet'] = train['tweet'].str.replace('[^a-zA-Z]','')\n",
    "#train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_more(text):\n",
    "    ''' remove text in square brackets, remove punctuation and remove words containing numbers if anyleft by now.'''\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "clean_pun_2 = lambda x: clean_more(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user when a father is dysfunctional and is so ...\n",
       "1    user user thanks for lyft credit i cant use ca...\n",
       "2                                  bihday your majesty\n",
       "3    model i love u take with u all the time in urð...\n",
       "4                    factsguide society now motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'] = train.tweet.apply(clean_pun_2)\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3)-Removal of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user father dysfunctional selfish drags kids d...\n",
       "1    user user thanks lyft credit cant use cause do...\n",
       "2                                       bihday majesty\n",
       "3                model love u take u time urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user father dysfunctional selfish drags kids dysfunction run'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user user thanks lyft credit cant use cause dont offer wheelchair vans pdx disapointed getthanked'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4)-Common word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user     17473\n",
       "love      2647\n",
       "ð         2522\n",
       "day       2199\n",
       "â         1797\n",
       "happy     1663\n",
       "amp       1582\n",
       "im        1139\n",
       "u         1136\n",
       "time      1110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let’s check the 10 most frequently occurring words in our text data\n",
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " remove these words as their presence will not of any use in classification of our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "life        1086\n",
       "like        1042\n",
       "today        991\n",
       "new          983\n",
       "positive     928\n",
       "thankful     919\n",
       "get          917\n",
       "people       852\n",
       "good         840\n",
       "bihday       825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that we have got a better list of most frequent words now than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father dysfunctional selfish drags kids dysfunction run'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks lyft credit cant use cause dont offer wheelchair vans pdx disapointed getthanked'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5)-Rare words removal\n",
    "Let’s remove rarely occurring words from the text. Because they’re so rare, the association between them and other words is dominated by noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nerdpay              1\n",
       "weloveclothespins    1\n",
       "brundlefly           1\n",
       "turâ                 1\n",
       "xamena               1\n",
       "sec                  1\n",
       "sweatisfatcrying     1\n",
       "feelingwashedout     1\n",
       "àààà                 1\n",
       "beardhat             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freemasons    1\n",
       "nug           1\n",
       "ðððððªðª      1\n",
       "dadâï         1\n",
       "timeðª        1\n",
       "noclothes     1\n",
       "ahhhhhh       1\n",
       "circuit       1\n",
       "neednap       1\n",
       "tangerang     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are still words that are rare. Of course, we can have another round to remove them. For simplicity, let's keep it to one round **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6)- Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kiss dysfun...\n",
       "1    thanks left credit can use cause dont offer wh...\n",
       "2                                       midday majesty\n",
       "3                               model take or ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the textblob library\n",
    "from textblob import TextBlob\n",
    "train['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model take urð ðððð ððð has been converted to orð ðððð ððð. It is not correct still. There are chances of getting some more mistakes. In tweets , mostly slang language is used. So, this may not be very helpful technique to apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7)-Tokenization\n",
    "Tokenization refers to dividing the text into a sequence of words or sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['thanks', 'lyft', 'credit', 'cant', 'use', 'cause', 'dont', 'offer', 'wheelchair', 'vans', 'pdx', 'disapointed', 'getthanked'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(train['tweet'][1]).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8)- Stemming\n",
    "Stemming refers to the removal of suffices, like “ing”, “ly”, “s”, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        father dysfunct selfish drag kid dysfunct run\n",
       "1    thank lyft credit cant use caus dont offer whe...\n",
       "2                                       bihday majesti\n",
       "3                              model take urð ðððð ððð\n",
       "4                              factsguid societi motiv\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['tweet'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father dysfunctional selfish drags kids dysfunction run'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9)-Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is a more effective option than stemming because it converts the word into its root word, rather than just stripping the suffices. It makes use of the vocabulary and does a morphological analysis to obtain the root word. Therefore, we usually prefer using lemmatization over stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drag kid dysfunct...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father dysfunctional selfish drag kid dysfunction run'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks lyft credit cant use cause dont offer wheelchair van pdx disapointed getthanked'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)-Advance Text Processing\n",
    "- N-grams\n",
    "- Term Frequency\n",
    "- Inverse Document Frequency\n",
    "- Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "- Bag of Words\n",
    "- Sentiment Analysis\n",
    "- Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1)-N-gram\n",
    "N-grams are the combination of multiple words used together. Ngrams with N=1 are called unigrams. Similarly, bigrams (N=2), trigrams (N=3) and so on can also be used.\n",
    "\n",
    "Unigrams do not usually contain as much information as compared to bigrams and trigrams. The basic principle behind n-grams is that they capture the language structure, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with. Optimum length really depends on the application – if your n-grams are too short, you may fail to capture important differences. On the other hand, if they are too long, you may fail to capture the “general knowledge” and only stick to particular cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father dysfunctional selfish drag kid dysfunction run'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['father', 'dysfunctional']),\n",
       " WordList(['dysfunctional', 'selfish']),\n",
       " WordList(['selfish', 'drag']),\n",
       " WordList(['drag', 'kid']),\n",
       " WordList(['kid', 'dysfunction']),\n",
       " WordList(['dysfunction', 'run'])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(train['tweet'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2)-Term frequency\n",
    "Term frequency is simply the ratio of the count of a word present in a sentence, to the length of the sentence.\n",
    "\n",
    "Therefore, we can generalize term frequency as:\n",
    "\n",
    "TF = (Number of times term T appears in the particular row) / (number of terms in that row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lyft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pdx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>offer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disapointed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf\n",
       "0        credit   1\n",
       "1          dont   1\n",
       "2           use   1\n",
       "3          lyft   1\n",
       "4           van   1\n",
       "5           pdx   1\n",
       "6    wheelchair   1\n",
       "7        thanks   1\n",
       "8         cause   1\n",
       "9          cant   1\n",
       "10        offer   1\n",
       "11  disapointed   1\n",
       "12   getthanked   1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (train['tweet'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3)-Inverse Document Frequency\n",
    "\n",
    "The intuition behind inverse document frequency (IDF) is that a word is not of much use to us if it’s appearing in all the documents.\n",
    "\n",
    "Therefore, the IDF of each word is the log of the ratio of the total number of rows to the number of rows in which that word is present.\n",
    "\n",
    "IDF = log(N/n), where, N is the total number of rows and n is the number of rows in which the word was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit</td>\n",
       "      <td>1</td>\n",
       "      <td>7.327781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont</td>\n",
       "      <td>1</td>\n",
       "      <td>3.746911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "      <td>3.574363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lyft</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>5.236505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pdx</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>1</td>\n",
       "      <td>9.273691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>4.597751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>5.690172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cant</td>\n",
       "      <td>1</td>\n",
       "      <td>3.542509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>offer</td>\n",
       "      <td>1</td>\n",
       "      <td>6.522155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disapointed</td>\n",
       "      <td>1</td>\n",
       "      <td>10.372303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>1</td>\n",
       "      <td>9.679156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf        idf\n",
       "0        credit   1   7.327781\n",
       "1          dont   1   3.746911\n",
       "2           use   1   3.574363\n",
       "3          lyft   1   8.762865\n",
       "4           van   1   5.236505\n",
       "5           pdx   1   8.762865\n",
       "6    wheelchair   1   9.273691\n",
       "7        thanks   1   4.597751\n",
       "8         cause   1   5.690172\n",
       "9          cant   1   3.542509\n",
       "10        offer   1   6.522155\n",
       "11  disapointed   1  10.372303\n",
       "12   getthanked   1   9.679156"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['tweet'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The more the value of IDF, the more unique is the word.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4)-Term Frequency – Inverse Document Frequency (TF-IDF)\n",
    "TF-IDF is the multiplication of the TF and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit</td>\n",
       "      <td>1</td>\n",
       "      <td>7.327781</td>\n",
       "      <td>7.327781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont</td>\n",
       "      <td>1</td>\n",
       "      <td>3.746911</td>\n",
       "      <td>3.746911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "      <td>3.574363</td>\n",
       "      <td>3.574363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lyft</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>5.236505</td>\n",
       "      <td>5.236505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pdx</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>1</td>\n",
       "      <td>9.273691</td>\n",
       "      <td>9.273691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>4.597751</td>\n",
       "      <td>4.597751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>5.690172</td>\n",
       "      <td>5.690172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cant</td>\n",
       "      <td>1</td>\n",
       "      <td>3.542509</td>\n",
       "      <td>3.542509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>offer</td>\n",
       "      <td>1</td>\n",
       "      <td>6.522155</td>\n",
       "      <td>6.522155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disapointed</td>\n",
       "      <td>1</td>\n",
       "      <td>10.372303</td>\n",
       "      <td>10.372303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>1</td>\n",
       "      <td>9.679156</td>\n",
       "      <td>9.679156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf        idf      tfidf\n",
       "0        credit   1   7.327781   7.327781\n",
       "1          dont   1   3.746911   3.746911\n",
       "2           use   1   3.574363   3.574363\n",
       "3          lyft   1   8.762865   8.762865\n",
       "4           van   1   5.236505   5.236505\n",
       "5           pdx   1   8.762865   8.762865\n",
       "6    wheelchair   1   9.273691   9.273691\n",
       "7        thanks   1   4.597751   4.597751\n",
       "8         cause   1   5.690172   5.690172\n",
       "9          cant   1   3.542509   3.542509\n",
       "10        offer   1   6.522155   6.522155\n",
       "11  disapointed   1  10.372303  10.372303\n",
       "12   getthanked   1   9.679156   9.679156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the TF-IDF has penalized words like ‘don’t’, ‘can’t’, and ‘use’ because they are commonly occurring words. However, it has given a high weight to “disappointed” since that will be very useful in determining the sentiment of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply to all\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113368 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dense data and also store as document term matrix of tf-idf\n",
    "tfidf_dtm = pd.DataFrame(train_vect.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adult</th>\n",
       "      <th>...</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïð</th>\n",
       "      <th>ðâ</th>\n",
       "      <th>ðâï</th>\n",
       "      <th>ðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ððððð</th>\n",
       "      <th>ðððððð</th>\n",
       "      <th>ó¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448983</td>\n",
       "      <td>0.496101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  action  actor  actually  adapt  add  adult  \\\n",
       "0   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0    0.0   \n",
       "1   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0    0.0   \n",
       "2   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0    0.0   \n",
       "3   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0    0.0   \n",
       "4   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0    0.0   \n",
       "\n",
       "  ...    âï  âïð   ðâ  ðâï   ðð       ððð      ðððð  ððððð  ðððððð   ó¾  \n",
       "0 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0     0.0  0.0  \n",
       "1 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0     0.0  0.0  \n",
       "2 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0     0.0  0.0  \n",
       "3 ...   0.0  0.0  0.0  0.0  0.0  0.448983  0.496101    0.0     0.0  0.0  \n",
       "4 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0     0.0  0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 1000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can always take it to term-document matrix.\n",
    "tfidf_tdm=tfidf_dtm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31952</th>\n",
       "      <th>31953</th>\n",
       "      <th>31954</th>\n",
       "      <th>31955</th>\n",
       "      <th>31956</th>\n",
       "      <th>31957</th>\n",
       "      <th>31958</th>\n",
       "      <th>31959</th>\n",
       "      <th>31960</th>\n",
       "      <th>31961</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31962 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      \\\n",
       "able          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "absolutely    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "account       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "act           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "action        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "            9      ...    31952  31953  31954  31955  31956  31957  31958  \\\n",
       "able          0.0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "absolutely    0.0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "account       0.0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "act           0.0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "action        0.0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "            31959  31960  31961  \n",
       "able          0.0    0.0    0.0  \n",
       "absolutely    0.0    0.0    0.0  \n",
       "account       0.0    0.0    0.0  \n",
       "act           0.0    1.0    0.0  \n",
       "action        0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 31962 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31962)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tdm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5)-Bag of Words\n",
    "Bag of Words (BoW) refers to the representation of text which describes the presence of words within the text data. The intuition behind this is that two similar text fields will contain similar kind of words, and will therefore have a similar bag of words. Further, that from the text alone we can learn something about the meaning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 127755 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['tweet'])\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6)-Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (-0.3, 0.5354166666666667)\n",
       "1                    (0.2, 0.2)\n",
       "2                    (0.0, 0.0)\n",
       "3                    (0.0, 0.0)\n",
       "4                    (0.0, 0.0)\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the sentiment of the first few tweets\n",
    "\n",
    "train['tweet'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it returns a tuple representing polarity and subjectivity of each tweet. Here, we only extract polarity as it indicates the sentiment as value nearer to 1 means a positive sentiment and values nearer to -1 means a negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks lyft credit cant use cause dont offer w...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model take urð ðððð ððð</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  father dysfunctional selfish drag kid dysfunct...       -0.3\n",
       "1  thanks lyft credit cant use cause dont offer w...        0.2\n",
       "2                                     bihday majesty        0.0\n",
       "3                            model take urð ðððð ððð        0.0\n",
       "4                      factsguide society motivation        0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['tweet','sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7)-Word Embeddings\n",
    "Word Embedding is the representation of text in the form of vectors. The underlying idea here is that similar words will have a minimum distance between their vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec\n",
    "\n",
    "Word2Vec models require a lot of text, so either we can train it on our training data or we can use the pre-trained word vectors developed by Google, Wiki, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying glove for word embedding\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say our tweet contains a text saying ‘go away’. We can easily obtain it’s word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.078894,  0.4616  ,  0.57779 , -0.71637 , -0.13121 ,  0.4186  ,\n",
       "       -0.29156 ,  0.52006 ,  0.089986, -0.35062 ,  0.51755 ,  0.51998 ,\n",
       "        0.15218 ,  0.41485 , -0.12377 , -0.37222 ,  0.0273  ,  0.75673 ,\n",
       "       -0.8739  ,  0.58935 ,  0.46662 ,  0.62918 ,  0.092603, -0.012868,\n",
       "       -0.015169,  0.25567 , -0.43025 , -0.77668 ,  0.71449 , -0.3834  ,\n",
       "       -0.69638 ,  0.23522 ,  0.11396 ,  0.02778 ,  0.071357,  0.87409 ,\n",
       "       -0.1281  ,  0.063576,  0.067867, -0.50181 , -0.28523 , -0.072536,\n",
       "       -0.50738 , -0.6914  , -0.53579 , -0.11361 , -0.38234 , -0.12414 ,\n",
       "        0.011214, -1.1622  ,  0.037057, -0.18495 ,  0.01416 ,  0.87193 ,\n",
       "       -0.097309, -2.3565  , -0.14554 ,  0.28275 ,  2.0053  ,  0.23439 ,\n",
       "       -0.38298 ,  0.69539 , -0.44916 , -0.094157,  0.90527 ,  0.65764 ,\n",
       "        0.27628 ,  0.30688 , -0.57781 , -0.22987 , -0.083043, -0.57236 ,\n",
       "       -0.299   , -0.81112 ,  0.039752, -0.05681 , -0.48879 , -0.18091 ,\n",
       "       -0.28152 , -0.20559 ,  0.4932  , -0.033999, -0.53139 , -0.28297 ,\n",
       "       -1.4475  , -0.18685 ,  0.091177,  0.11454 , -0.28168 , -0.33565 ,\n",
       "       -0.31663 , -0.1089  ,  0.10111 , -0.23737 , -0.64955 , -0.268   ,\n",
       "        0.35096 ,  0.26352 ,  0.59397 ,  0.26741 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10379 , -0.014792,  0.59933 , -0.51316 , -0.036463,  0.6588  ,\n",
       "       -0.57906 ,  0.17819 ,  0.23663 , -0.21384 ,  0.55339 ,  0.53597 ,\n",
       "        0.041444,  0.16095 ,  0.017093, -0.37242 ,  0.017974,  0.39268 ,\n",
       "       -0.23265 ,  0.1818  ,  0.66405 ,  0.98163 ,  0.42339 ,  0.030581,\n",
       "        0.35015 ,  0.25519 , -0.71182 , -0.42184 ,  0.13068 , -0.47452 ,\n",
       "       -0.08175 ,  0.1574  , -0.13262 ,  0.22679 , -0.16885 , -0.11122 ,\n",
       "       -0.32272 , -0.020978, -0.43345 ,  0.172   , -0.67366 , -0.79052 ,\n",
       "        0.10556 , -0.4219  , -0.12385 , -0.063486, -0.17843 ,  0.56359 ,\n",
       "        0.16986 , -0.17804 ,  0.13956 , -0.20169 ,  0.078985,  1.4497  ,\n",
       "        0.23556 , -2.6014  , -0.5286  , -0.11636 ,  1.7184  ,  0.33254 ,\n",
       "        0.12136 ,  1.1602  , -0.2914  ,  0.47125 ,  0.41869 ,  0.35271 ,\n",
       "        0.47869 , -0.042281, -0.18294 ,  0.1796  , -0.24431 , -0.34042 ,\n",
       "        0.20337 , -0.93676 ,  0.013077,  0.080339, -0.36604 , -0.44005 ,\n",
       "       -0.35393 ,  0.15907 ,  0.55807 ,  0.1492  , -0.86433 ,  0.040305,\n",
       "       -1.0939  , -0.26386 , -0.29494 ,  0.25696 , -0.33718 , -0.086468,\n",
       "       -0.24246 , -0.21114 ,  0.099632,  0.12815 , -0.78714 , -0.51785 ,\n",
       "       -0.10944 ,  0.9763  ,  0.57032 ,  0.13581 ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['away']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the average to represent the string ‘go away’ in the form of vectors having 100 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.091342  ,  0.223404  ,  0.58856   , -0.614765  , -0.0838365 ,\n",
       "        0.5387    , -0.43531   ,  0.349125  ,  0.163308  , -0.28223   ,\n",
       "        0.53547   ,  0.52797496,  0.096812  ,  0.2879    , -0.0533385 ,\n",
       "       -0.37232   ,  0.022637  ,  0.574705  , -0.553275  ,  0.385575  ,\n",
       "        0.565335  ,  0.805405  ,  0.2579965 ,  0.0088565 ,  0.1674905 ,\n",
       "        0.25543   , -0.571035  , -0.59926   ,  0.422585  , -0.42896   ,\n",
       "       -0.389065  ,  0.19631   , -0.00933   ,  0.127285  , -0.0487465 ,\n",
       "        0.381435  , -0.22540998,  0.021299  , -0.1827915 , -0.16490501,\n",
       "       -0.47944498, -0.431528  , -0.20091   , -0.55665   , -0.32982   ,\n",
       "       -0.088548  , -0.28038502,  0.219725  ,  0.090537  , -0.67012   ,\n",
       "        0.0883085 , -0.19332   ,  0.0465725 ,  1.160815  ,  0.0691255 ,\n",
       "       -2.47895   , -0.33707   ,  0.083195  ,  1.86185   ,  0.283465  ,\n",
       "       -0.13081   ,  0.927795  , -0.37028   ,  0.1885465 ,  0.66198   ,\n",
       "        0.505175  ,  0.37748498,  0.1322995 , -0.380375  , -0.025135  ,\n",
       "       -0.1636765 , -0.45639   , -0.047815  , -0.87394   ,  0.0264145 ,\n",
       "        0.0117645 , -0.427415  , -0.31048   , -0.317725  , -0.02326   ,\n",
       "        0.525635  ,  0.05760051, -0.69786   , -0.1213325 , -1.2707    ,\n",
       "       -0.225355  , -0.1018815 ,  0.18575001, -0.30943   , -0.211059  ,\n",
       "       -0.279545  , -0.16002001,  0.100371  , -0.05461   , -0.71834505,\n",
       "       -0.392925  ,  0.12075999,  0.61991   ,  0.582145  ,  0.20161   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model['go'] + model['away'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have converted the entire string into a vector which can now be used as a feature in any modelling technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
